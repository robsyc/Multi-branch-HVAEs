from torch_geometric.utils.smiles import x_map, e_map
import torch
import torch.nn.functional as F
from torch.nn import ModuleList, Embedding, Linear, LeakyReLU, BatchNorm1d
from torch_geometric.nn import GATv2Conv, SAGPooling, global_max_pool as gmp
from torch_geometric.utils import to_dense_adj


class AtomEncoder(torch.nn.Module):
    """
    Encodes chemical atom node feature vector (long 64-bit int) 
    to a fixed size embedding vecor (32-bit float).
    Equivalent to a one-hot encoding followed by a linear layer.
    Args:
        - emb_dim: size of the embedding vector (default: 64)

    Also see implementations by OGB (Open Graph Benchmark): 
        - https://github.com/pyg-team/pytorch_geometric/blob/master/examples/multi_gpu/distributed_batching.py#L27
        - https://github.com/snap-stanford/ogb/blob/master/ogb/graphproppred/mol_encoder.py
    """
    def __init__(self, emb_dim=64):
        super(AtomEncoder, self).__init__()
        self.atom_embedding_list = ModuleList()
        full_atom_feature_dims = list(map(len, [key for key in x_map.values()]))

        for i, dim in enumerate(full_atom_feature_dims):
            emb = Embedding(dim, emb_dim)
            torch.nn.init.xavier_uniform_(emb.weight.data)
            self.atom_embedding_list.append(emb)

    def forward(self, x):
        x_embedding = 0
        for i in range(x.shape[1]):
            x_embedding += self.atom_embedding_list[i](x[:,i])

        return x_embedding

class BondEncoder(torch.nn.Module):
    """
    Encodes chemical bond feature vector (long 64-bit int) 
    to a fixed size embedding vecor (32-bit float)
    Parameters:
        emb_dim: size of the embedding vector (default: 16)
    """
    def __init__(self, emb_dim=16):
        super(BondEncoder, self).__init__()
        self.bond_embedding_list = ModuleList()
        full_bond_feature_dims = list(map(len, [key for key in e_map.values()]))

        for i, dim in enumerate(full_bond_feature_dims):
            emb = Embedding(dim, emb_dim)
            torch.nn.init.xavier_uniform_(emb.weight.data)
            self.bond_embedding_list.append(emb)

    def forward(self, edge_attr):
        bond_embedding = 0
        for i in range(edge_attr.shape[1]):
            bond_embedding += self.bond_embedding_list[i](edge_attr[:,i])

        return bond_embedding


class MolGraphVAEncoder(torch.nn.Module):
    """
    Variational Molecular Graph Auto-Encoder Encoder-block 
    with Atom and BondEncoders, GATv2Conv layers and global pooling.
    Args:
        - node_dim (int): Number of input features per node
        - edge_dim (int): Number of input features per edge
        - hidden_channels (int): Number of hidden units
        - latent_dim (int): Dimensionality of VAE variables' latent space
        - heads (int): Number of multi-head-attention heads
        - dropout (float): Dropout probability
        - subgraphs (list): List of subgraph dimensions
    Forward:
        - subgraphs: List of subgraphs generated by the hidden hierarchical layers.
        - mu: Mean of the latent space.
        - logstd: Logarithm of the standard deviation of the latent space.

    Also see implementations by:
        - GraphDTA (GATConv, dimensions, ...) https://github.com/thinng/GraphDTA/blob/master/models/gat.py
        - NGG (encoder, decoder, ... TODO their use of GIN could be interesting) https://github.com/iakovosevdaimon/Neural-Graph-Generator/blob/main/autoencoder.py
    """
    def __init__(self, node_dim=64, edge_dim=16, hidden_channels=64, latent_dim=64, heads=8, dropout=0.2, subgraphs=[25, 12, 6]):
        super(MolGraphVAEncoder, self).__init__()
        self.subgraphs = subgraphs
        self.dropout = dropout
        self.hidden_dim = hidden_channels * heads

        self.atom_encoder = AtomEncoder(emb_dim=node_dim)
        self.bond_encoder = BondEncoder(emb_dim=edge_dim)

        self.conv = GATv2Conv(node_dim, hidden_channels, heads=heads, edge_dim=edge_dim)
        self.bn = BatchNorm1d(self.hidden_dim)
        self.conv_layers = ModuleList()
        self.bn_layers = ModuleList()
        self.pool_layers = ModuleList()
        for subgraph_size in subgraphs:
            self.conv_layers.append(GATv2Conv(self.hidden_dim, hidden_channels, heads=heads, edge_dim=edge_dim))
            self.bn_layers.append(BatchNorm1d(self.hidden_dim))
            self.pool_layers.append(SAGPooling(self.hidden_dim, ratio=subgraph_size, GNN=GATv2Conv)) # https://github.com/pyg-team/pytorch_geometric/blob/master/torch_geometric/nn/pool/sag_pool.py

        self.fc_mean = Linear(self.hidden_dim, latent_dim)
        self.fc_logvar = Linear(self.hidden_dim, latent_dim)
    
    def forward(self, data, debug=False):
        adj_matrices = []
        x, edge_index, edge_attr, batch = data.x, data.edge_index, data.edge_attr, data.batch

        # Initialize out based on batch size
        try:
            out = torch.zeros((data.num_graphs, self.hidden_dim), device=x.device)
        except AttributeError:
            out = torch.zeros((1, self.hidden_dim), device=x.device)

        # Atom and bond encoding
        x = self.atom_encoder(x)
        edge_attr = self.bond_encoder(edge_attr)
        if debug:
            print("Data: ", x.shape, edge_index.shape, edge_attr.shape)
            print("Embeddings: ", x.shape, edge_attr.shape)
            print("Output: ", out.shape)

        # Base convolution and pooling
        x = self.conv(x, edge_index, edge_attr)
        x = self.bn(x)
        out += gmp(x, batch)
        if debug:
            print("First convolution: ", x.shape, edge_index.shape, edge_attr.shape)

        # Iterative hierarchical convolution and pooling
        for i, subgraph_size in enumerate(self.subgraphs):
            x = self.conv_layers[i](x, edge_index, edge_attr)
            x = self.bn_layers[i](x)
            x = F.dropout(x, self.dropout, training=self.training)
            if debug:
                print("\nConvolution: ", x.shape, edge_index.shape, edge_attr.shape)

            subgraph = self.pool_layers[i](x, edge_index, edge_attr, batch)
            x, edge_index, edge_attr, batch, perm, score = subgraph
            out += gmp(x, batch)
            # perm: indices of nodes in the original graph that are kept
            # score: attention scores of each kept node

            try:
                adj = to_dense_adj(edge_index, batch=batch, max_num_nodes=subgraph_size, batch_size=data.num_graphs)
            except AttributeError:
                adj = to_dense_adj(edge_index, max_num_nodes=subgraph_size)
            # adj_reordered = adj[:, perm][:, :, perm]  # TODO: reorder adj to canonical form?
            adj_matrices.append(adj)
            if debug:
                print("Pooling: ", x.shape, edge_index.shape, edge_attr.shape)
                print("Adjacency: ", adj.shape)

        mean = self.fc_mean(out)
        logvar = self.fc_logvar(out)
        return mean, logvar, adj_matrices

class MolGraphVADecoder(torch.nn.Module):
    """
    Variational Molecular Graph Auto-Encoder Decoder-block
    with FC layers reconstructing the adjacency matrix.
    Args:
        - latent_dim (int): Dimensionality of resampled Z from mean and logstd encoding.
        - hidden_channels (int): Number of hidden units.
        - subgraphs (list): List of subgraph dimensions.
        - n_nodes (int): Maximum number of nodes in the graph and size of the final output graph.
    Forward:
        - adj_matrices: Reconstructed adjacency matrices. TODO more to generate? features?
    Also see implementations by:
        - NGG (encoder, decoder, ...) https://github.com/iakovosevdaimon/Neural-Graph-Generator/blob/7073338a8a41c18d5963c275157bafa3cc9f735f/autoencoder.py#L10
    """
    def __init__(self, latent_dim=64, hidden_channels=64, subgraphs=[6, 12, 25], n_nodes=50):
        super(MolGraphVADecoder, self).__init__()
        self.n_nodes = n_nodes
        self.subgraphs = subgraphs

        self.relu = LeakyReLU()
        self.fc_layers = ModuleList()
        self.unpool_layers = ModuleList()
        for i in range (n_layers):
            if i == 0:
                self.fc_layers.append(Linear(latent_dim, hidden_channels))
            else:
                self.fc_layers.append(Linear(hidden_channels, hidden_channels))
            

        self.fc1 = Linear(latent_dim, hidden_channels)
        self.fc2 = Linear(hidden_channels, hidden_channels)
        self.fc3 = Linear(hidden_channels, 2 * n_nodes * (n_nodes - 1) // 2) # adj matrix minus diagonal
        self.relu = LeakyReLU()
    
    def forward(self, x):
        x = self.relu(self.fc1(x))
        x = self.relu(self.fc2(x))
        x = self.fc3(x)
        x = torch.reshape(x, (x.size(0), -1, 2)) # reshape to two halves of symmetric adjacency matrix
        x = torch.nn.functional.gumbel_softmax(
            x, tau=1, hard=True)[:,:,0] # sample from categorical distribution, mashing both halves
        adj = torch.zeros(x.size(0), self.n_nodes, self.n_nodes, device=x.device) # empty adjacency matrix
        idx = torch.triu_indices(self.n_nodes, self.n_nodes, 1) # indices for upper triangular part
        adj[:, idx[0], idx[1]] = x # fill upper triangular part with sampled values
        adj = adj + torch.transpose(adj, 1, 2) # make adjacency matrix symmetric

        # TODO edge and node features?!
        return adj
    
class MolGraphVAE(torch.nn.Module):
    """
    Variational Molecular Graph Auto-Encoder with MolGraphVAEncoder and Decoder-block.
    Input:
        - node_dim: Number of input features per node.
        - edge_dim: Number of input features per edge.
        - n_max_nodes: Maximum number of nodes in the graph.
        - hidden_channels: Number of hidden units.
        - latent_dim: Dimensionality of VAE variables' latent space (mu and logstd).
        - heads: Number of multi-head-attention heads.
        - dropout: Dropout probability.
    Returns:

    Also see implementations by:
        - NGG (encoder, decoder, loss) https://github.com/iakovosevdaimon/Neural-Graph-Generator/blob/7073338a8a41c18d5963c275157bafa3cc9f735f/autoencoder.py#L134
        - DGraphDTA (dropout, protein features, hyperparams, ...) Jiang-2020-DOI: 10.1039/d0ra02297g
        - Node ordering (Li et al 2018 Learning deep generative models of graphs)
    """
    def __init__(self, node_dim=64, edge_dim=16, n_max_nodes=50, hidden_channels=64, latent_dim=64, heads=8, dropout=0.2):
        super(MolGraphVAE, self).__init__()
        self.n_nodes = n_max_nodes
        self.encoder = MolGraphVAEncoder(node_dim=node_dim, edge_dim=edge_dim, hidden_channels=hidden_channels, latent_dim=latent_dim, heads=heads, dropout=dropout)
        self.decoder = MolGraphVADecoder(latent_dim=latent_dim, hidden_channels=hidden_channels, n_nodes=n_max_nodes)
    
    def reparameterize(self, mean, logvar, eps_scale=1.):
        """Use the reparameterization trick to sample z from the VAE latent space.
        TODO check with promotors if this is the right way to do it."""
        if self.training:
            std = logvar.mul(0.5).exp_()            # sampling from std directly is not allowed in backpropagation
            eps = torch.randn_like(std) * eps_scale # random Gaussian noise from which to sample (same shape as std)
            return eps.mul(std).add_(mean)
        else:
            return mean

    def encode(self, data):
        # TODO MoVAE suggests encoding nodes & edges separately...
        mean, logvar = self.encoder(data)
        z = self.reparameterize(mean, logvar)
        return mean, logvar
    
    def decode(self, z):
        adj = self.decoder(z)
        return adj

    def forward(self, data):
        mean, logvar = self.encode(data)
        z = self.reparameterize(mean, logvar)
        adj = self.decode(z)
        # x_reconstructed?!?!
        return adj
    
    def loss_function(self, data, mean, logvar, adj, beta=0.05):
        # TODO makes more sense to perform graph comparison instead of adjacency matrix comparison
        # - supposedly this should work fine because of RDKit's canonical SMILES-based ordering
        # - learned ordering?!
        # - adversarial training?!
        recon_loss = torch.nn.functional.l1_loss(adj, to_dense_adj(data.edge_index, max_num_nodes=self.n_nodes), reduction='sum')
        kld_loss = -0.5 * torch.sum(1 + logvar - mean.pow(2) - logvar.exp())
        loss = recon_loss + beta * kld_loss
        return loss, recon_loss, kld_loss